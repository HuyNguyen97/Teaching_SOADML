{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent and Stochastic Gradient Descent\n",
    "\n",
    "Our goal is to minimize a convex differentiable function $f: \\mathbb{R}^p \\to \\mathbb{R}$ using an iterative scheme. We implement here two such algorithms:\n",
    "* Gradient Descent\n",
    "* Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The intuition behind Gradient Descent\n",
    "\n",
    "The idea is to follow the direction of steepest descent. At point $\\theta \\in \\mathbb{R}^p$, the steepest descent direction is given by $- \\nabla f(\\theta)$. This suggests constructing a sequence $\\theta_1, \\ldots, \\theta_T$ by iterating the formula:\n",
    "$$\\theta_{k+1} = \\theta_k - \\gamma_k \\nabla f(\\theta_k)$$\n",
    "where $\\gamma_k > 0$ is a step-size. If the number of iterations $n$ is large enough, and if $(\\gamma_k)$ is well chosen, we can hope that the sequence $(\\theta_n)$ will converge to a point $\\theta^*$ minimizing $f$.\n",
    "\n",
    "<img style=\"margin-left:0\" width=\"300px\" src=\"https://upload.wikimedia.org/wikipedia/commons/f/ff/Gradient_descent.svg\" style=\"align:center\" />\n",
    "\n",
    "__Remark:__ If we only wish to minimize $f$ on a compact convex subset $\\Omega \\subset \\mathbb{R}^p$, we can use Projected Gradient Descent: at each step of gradient descent, we project back onto $\\Omega$, i.e.:\n",
    "$$\\theta_{k+1} = \\Pi_\\Omega \\left[\\theta_k - \\gamma_k \\nabla f(\\theta_k) \\right]$$\n",
    "where $\\Pi_\\Omega: \\mathbb{R}^p \\to \\Omega$ is the projection onto $\\Omega$:\n",
    "$$\\|\\theta - \\Pi_\\Omega(\\theta)\\| = \\min_{\\omega \\in \\Omega} \\|\\theta - \\omega\\|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Theoretical results\n",
    " For both Gradient Descent and Projected Gradient Descent, we have the following results.\n",
    " \n",
    "* If $f$ is a $L$-smooth function with minimum in $\\theta^*$, and if $\\gamma_k = \\frac{1}{L}$, then:\n",
    "$$ f(\\theta_k) - f(\\theta^*) \\leq \\frac{2L\\|\\theta_0-\\theta^*\\|^2}{k+4}$$\n",
    "* If moreover $f$ if $\\mu$-strongly convex, then:\n",
    "$$ f(\\theta_k) - f(\\theta^*) \\leq \\left(1 - \\frac{\\mu}{L}\\right)^k \\left[ f(\\theta_0) - f(\\theta^*) \\right]$$\n",
    "\n",
    "The rate of convergence of Gradient Descent adpats to strong-convexity (i.e. to the difficulty of the problem)\n",
    "\n",
    "\n",
    "*(Proofs of these results, as well as many other interestings results in optimization for Machine Learning, can be found in Francis Bach's slides : https://www.di.ens.fr/~fbach/fbach_orsay_2019.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first example: least squares\n",
    "\n",
    "Let $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$. We wish to minimize the function\n",
    "$$f(\\theta) = \\frac{1}{2}\\|y - X\\theta\\|^2.$$\n",
    "\n",
    "Here, we suppose that the observations $y$ were obtained by linear combination of data $X$, plus some noise $\\sigma \\xi$:\n",
    "$$ y = X w + \\sigma \\xi $$\n",
    "with $\\sigma > 0$ noise level and $\\xi \\sim \\mathcal{N}(0,I)$.\n",
    "\n",
    "We know that the minimum of $f$ is attained at\n",
    "$$\\theta^* = TODO$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data\n",
    "n, p = 10, 5\n",
    "\n",
    "X = np.random.randn(n,p)\n",
    "w = np.random.randn(p)\n",
    "\n",
    "sigma = 1.\n",
    "xi = np.random.randn(n)\n",
    "\n",
    "y = X.dot(w) + sigma*xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of function f and its gradient\n",
    "def f(theta):\n",
    "    '''Return the least squares error at point `theta`.'''\n",
    "    return 0.5 * np.linalg.norm(y - X.dot(theta))**2\n",
    "\n",
    "def grad_f(theta):\n",
    "    '''Return the gradient of least squares error at point `theta`.'''\n",
    "    return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of f\n",
    "theta_star = # TODO\n",
    "\n",
    "print('The minimum value of function `f` is =', f(theta_star))\n",
    "print('It is attained at point theta^* =', theta_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running Gradient Descent, we need to set the step size $\\gamma = \\frac{1}{L}$, where $L$ is the Lipschitz constant of $\\nabla f$: \n",
    "\n",
    "$$L = TODO$$\n",
    "\n",
    "We can now run Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations to be run\n",
    "max_iter = 100\n",
    "\n",
    "# Lists to save the sequences theta, f(theta), grad_f(theta)\n",
    "theta_history = []\n",
    "f_history = []\n",
    "grad_f_history = []\n",
    "\n",
    "# Step size\n",
    "L = # TODO\n",
    "step_size = # TODO\n",
    "\n",
    "# Random initial point\n",
    "theta = np.random.randn(p)\n",
    "\n",
    "# Gradient Descent Iterations\n",
    "for t in range(max_iter):\n",
    "    theta = # TODO\n",
    "    \n",
    "    theta_history.append(theta)\n",
    "    f_history.append(f(theta))\n",
    "    grad_f_history.append(grad_f(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vizualize the convergence of Gradient Descent in three different ways:\n",
    "* The sequence $f(\\theta_k) - f(\\theta^*) \\rightarrow 0$\n",
    "* The sequence $\\|\\nabla f(\\theta_k)\\| \\rightarrow 0$\n",
    "* The sequence $\\theta_k \\rightarrow \\theta^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of values of `f`, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of the norm of the gradient of `f`, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of the norm of `theta`, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second example: logistic regression\n",
    "\n",
    "We have data $x_1, \\ldots, x_n \\in \\mathbb{R}^n$ that belong to one of the two classes $1$ or $-1$, and we write $y_i$ th class of datum $x_i$. We suppose that we observe noisy clusters that are originally linearly separable, i.e.\n",
    "$$ y_i = \\text{sign} \\left( w^T x_i + \\sigma \\xi_i \\right) $$\n",
    "where $\\sigma > 0$ is the noise level and $\\xi_1, \\ldots, \\xi_n \\sim \\mathcal{N}(0,1)$ are i.i.d.\n",
    "\n",
    "We want to learn a logistic regressor on this data, i.e. we want to find $\\theta^* \\in \\mathbb{R}^p$ minimizing\n",
    "$$ f(\\theta) = \\frac{1}{n}\\sum_{i=1}^n \\log\\left( 1 + e^{-y_i \\theta^T x_i} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data\n",
    "n, p = 10, 5\n",
    "\n",
    "X = np.random.randn(n, p)\n",
    "w = np.random.randn(p)\n",
    "\n",
    "sigma = 1\n",
    "xi = np.random.randn(n)\n",
    "\n",
    "y = np.sign(X.dot(w) + sigma*xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta):\n",
    "    '''Return the logistic loss for parameters `theta`.'''\n",
    "    return np.mean(np.log(1.0 + np.exp(-y*X.dot(theta))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute the gradient of $f$ at point $\\theta$:\n",
    "$$ \\nabla f(\\theta) = TODO $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the gradient of f\n",
    "def grad_f(theta):\n",
    "    '''Return the gardient of the logistic loss `f` at point `theta`.'''\n",
    "    return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations to be run\n",
    "max_iter = 100\n",
    "\n",
    "# Lists to save the sequences theta, f(theta), grad_f(theta)\n",
    "theta_history = []\n",
    "f_history = []\n",
    "grad_f_history = []\n",
    "\n",
    "# Step size\n",
    "L = # TODO\n",
    "step_size = # TODO\n",
    "\n",
    "# Random initial point\n",
    "theta = np.random.randn(p)\n",
    "\n",
    "# Gradient Descent Iterations\n",
    "for t in range(max_iter):\n",
    "    theta = # TODO\n",
    "    \n",
    "    theta_history.append(theta)\n",
    "    f_history.append(f(theta))\n",
    "    grad_f_history.append(grad_f(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now vizualize the convergence in terms of the values of $f$ and in terms of the norm of its gradient.\n",
    "\n",
    "The convergence is slower than for the least square regression. Both functions are smooth, but the logistic loss is not strongly convex. Theory then tells us that the convergence will be in $\\mathcal{O}(1/k)$ instead of $\\mathcal{O}(e^{-k})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_f = np.min(f_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of values of `f`, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of the gradient of `f`, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Intuition behind Stochastic Gradient Descent\n",
    "\n",
    "We wish to minimize a convex function $f : \\mathbb{R}^p \\to \\mathbb{R}$ of the form\n",
    "$$ f: \\theta \\to \\sum_{i=1}^n f_i(\\theta) $$\n",
    "where $f_1, \\ldots, f_n : \\mathbb{R}^p \\to \\mathbb{R}$ are smooth differentiable functions. In Machine Learning, such functions appear all the time with $f_i(\\theta)$ being the loss of the $i$-th datum.\n",
    "\n",
    "When the number of data $n$ becomes very large, as it is in real applications, computing the gradient of $f$ at each iteration of Gradient Descent may be too time consuming. Instead, we can only compute the gradient on one randomly-chosen datum $x_i$. We may need more iterations, but each iteration becomes very fast to compute.\n",
    "\n",
    "We thus consider the iterations:\n",
    "* Choose $i \\in [1 ; n]$ uniformly at random\n",
    "* $\\theta_{k+1} = \\theta_k - \\gamma_k \\nabla f_i(\\theta_k)$\n",
    "\n",
    "__Choice of step size $\\gamma_k$:__ Can be taken constant, or $\\approx 1/\\sqrt{k}$. *(More details can be found in https://www.di.ens.fr/~fbach/fbach_orsay_2019.pdf)*\n",
    "\n",
    "__Polyak-Rupert averaging:__ Instead of choosing for a minimizer $\\hat\\theta = \\theta_T$, i.e. the last computed value of $\\theta_k$, it is often better to choose $\\hat\\theta = \\frac{1}{T} \\sum_{k=1}^T \\theta_k$.\n",
    "\n",
    "![](http://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning_files/Image%20[16].png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first example: least squares\n",
    "\n",
    "Let $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$. We wish to minimize the function\n",
    "$$f(\\theta) = \\frac{1}{2}\\|y - X\\theta\\|^2.$$\n",
    "\n",
    "Here, we suppose that the observations $y$ were obtained by linear combination of data $X$, plus some noise $\\sigma \\xi$:\n",
    "$$ y = X w + \\sigma \\xi $$\n",
    "with $\\sigma > 0$ noise level and $\\xi \\sim \\mathcal{N}(0,I)$.\n",
    "\n",
    "We know that the minimum of $f$ is attained at\n",
    "$$\\theta^* = TODO$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data\n",
    "n, p = 10, 5\n",
    "\n",
    "X = np.random.randn(n,p)\n",
    "w = np.random.randn(p)\n",
    "\n",
    "sigma = 1.\n",
    "xi = np.random.randn(n)\n",
    "\n",
    "y = X.dot(w) + sigma*xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of function f and its gradient\n",
    "def f(theta):\n",
    "    '''Return the least squares error at point `theta`.'''\n",
    "    return 0.5 * np.linalg.norm(y - X.dot(theta))**2\n",
    "\n",
    "def grad_f(theta, i):\n",
    "    '''Return the gradient of least squares error at point `theta` for datum `i`.'''\n",
    "    return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of f\n",
    "theta_star = # TODO\n",
    "\n",
    "print('The minimum value of function `f` is =', f(theta_star))\n",
    "print('It is attained at point theta^* =', theta_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations to be run\n",
    "max_iter = 100*n\n",
    "\n",
    "# Lists to save the sequences theta, f(theta), theta_averaged, f(theta_averaged)\n",
    "theta_history = []\n",
    "f_history = []\n",
    "theta_averaged_history = []\n",
    "f_averaged_history = []\n",
    "\n",
    "# Step size\n",
    "L = # TODO\n",
    "step_size = # TODO\n",
    "\n",
    "# Random initial point\n",
    "theta = np.random.randn(p)\n",
    "theta_averaged = np.random.randn(p)\n",
    "\n",
    "# Gradient Descent Iterations\n",
    "for t in range(max_iter):\n",
    "    i = # TODO\n",
    "    \n",
    "    theta = # TODO\n",
    "    theta_averaged = # TODO\n",
    "    \n",
    "    theta_history.append(theta)\n",
    "    f_history.append(f(theta))\n",
    "    theta_averaged_history.append(theta_averaged)\n",
    "    f_averaged_history.append(f(theta_averaged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vizualize the convergence of Stochastic Gradient Descent for both the `last theta` and `averaged theta` approaches, in terms of:\n",
    "* The sequence $f(\\theta_k) - f(\\theta^*) \\rightarrow 0$\n",
    "* The sequence $\\theta_k \\rightarrow \\theta^*$\n",
    "\n",
    "TODO: comment on the choice between the two approaches using the following graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of values of `f`, for both approaches, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of the norm of `theta`, for both approaches, using a log-scale on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second example: logistic regression\n",
    "\n",
    "We have data $x_1, \\ldots, x_n \\in \\mathbb{R}^n$ that belong to one of the two classes $1$ or $-1$, and we write $y_i$ th class of datum $x_i$. We suppose that we observe noisy clusters that are originally linearly separable, i.e.\n",
    "$$ y_i = \\text{sign} \\left( w^T x_i + \\sigma \\xi_i \\right) $$\n",
    "where $\\sigma > 0$ is the noise level and $\\xi_1, \\ldots, \\xi_n \\sim \\mathcal{N}(0,1)$ are i.i.d.\n",
    "\n",
    "We want to learn a logistic regressor on this data, i.e. we want to find $\\theta^* \\in \\mathbb{R}^p$ minimizing\n",
    "$$ f(\\theta) = \\frac{1}{n}\\sum_{i=1}^n \\log\\left( 1 + e^{-y_i \\theta^T x_i} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data\n",
    "n, p = 100, 5\n",
    "\n",
    "X = np.random.randn(n, p)\n",
    "w = np.random.randn(p)\n",
    "\n",
    "sigma = 1\n",
    "xi = np.random.randn(n)\n",
    "\n",
    "y = np.sign(X.dot(w) + sigma*xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta):\n",
    "    '''Return the logistic loss for parameters `theta`.'''\n",
    "    return np.mean(np.log(1.0 + np.exp(-y*X.dot(theta))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the gradient of f\n",
    "def grad_f(theta, i):\n",
    "    '''Return the gardient of the logistic loss `f` at point `theta` for datum `i`.'''\n",
    "    return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations to be run\n",
    "max_iter = 1000*n\n",
    "\n",
    "# Lists to save the sequences theta, f(theta), theta_averaged, f(theta_averaged)\n",
    "theta_history = []\n",
    "f_history = []\n",
    "theta_averaged_history = []\n",
    "f_averaged_history = []\n",
    "\n",
    "# Step size\n",
    "L = # TODO\n",
    "step_size = # TODO\n",
    "\n",
    "# Random initial point\n",
    "theta = np.random.randn(p)\n",
    "\n",
    "# Gradient Descent Iterations\n",
    "for t in range(max_iter):\n",
    "    i = # TODO\n",
    "    \n",
    "    theta = # TODO\n",
    "    theta_averaged = # TODO\n",
    "    \n",
    "    theta_history.append(theta)\n",
    "    f_history.append(f(theta))\n",
    "    theta_averaged_history.append(theta_averaged)\n",
    "    f_averaged_history.append(f(theta_averaged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the approximative minimum value of `f`\n",
    "min_f = np.min([np.min(f_history), np.min(f_averaged_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the convergence in terms of values of `f`, for both approaches, using a log-scale on the y-axis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
